
\input{preambuleReport}



\title{New stochastic sketching methods for Big Data Ridge Regression}
\author{Cheikh Saliou Tour\'e \\ \\
Student at ENS Cachan\\\\
Tutor : Robert Gower \\ \\
Inria Paris (Sierra department)\\\\ }




\date{July, 2017}


\begin{document}

\renewcommand\bibname{References}
%\renewcommand\contentsname{Table of contents}
\maketitle


\begin{abstract}

//

\end{abstract}
\tableofcontents
\newpage

\chapter{Hadamard Sketches}

%\ecag{11}{green}{19}{
%\begin{definition}
%
%
%
%\end{definition} 
%}


\section{Algorithm}


\section{Convergence rate}

$Z = A S^{T} (S A S^{T})^{-1} S A$\\

$D = diag()$

$\rho = 1 - \lambda_{min}(A^{-\frac12}E[Z]A^{-\frac12}  )$

$S_{i} = I_{C_{i}} H.$\\

%$\bold{S} = [I_{C_{1}},I_{C_{2}},\dots,I_{C_{r}}] H$.\\
Denote $I_{C} = [I_{C_{1}},I_{C_{2}},\dots,I_{C_{r}}].$\\
$\tilde{A} = H A H^{T}.$\\

%$E[Z] = (A \bold{S}^{T} D) (D \bold{S} A) = (A H^{T} I_{C}^{T} D) (D I_{C} H A) = $

$A^{-\frac12}E[Z]A^{-\frac12} = E[A^{\frac 12} S^{T} (S A S^{T})^{-1} S A^{\frac 12} ] = \dsp\sum\limits_{i} p_{i} A^{\frac 12} H^{T} I_{C_{i}}^{T} (I_{C_{i}} H A H^{T} I_{C_{i}}^{T})^{-1} I_{C_{i}} H A^{\frac 12} \\
= A^{\frac 12} H^{T}E[ I_{C}^{T} (I_{C} \tilde{A} I_{C}^{T})^{-1} I_{C} ] H A^{\frac 12}  = H^{T} \tilde{A}^{\frac 12} E[ I_{C}^{T} (I_{C} \tilde{A} I_{C}^{T})^{-1} I_{C} ] \tilde{A}^{\frac 12} H $.\\
Hence :\\

$\rho = 1 - \lambda_{min}(A^{-\frac12}E[Z]A^{-\frac12}) = 1 - \lambda_{min}(H^{T} \tilde{A}^{\frac 12} E[ I_{C}^{T} (I_{C} \tilde{A} I_{C}^{T})^{-1} I_{C} ] \tilde{A}^{\frac 12} H ) = $



We recognize the convergence rate in the Randomized Newton Method and then, denoting by $\rho_{Newton}(M)$ the convergence rate of the Newton method associated with the definite positive matrix $M$, we obtain that :\\
$\rho = \rho_{Newton}$



\chapter{Conclusion}

\appendix
\begin{thebibliography}{1}

\bibitem{}
{\sc Robert Gower and Peter Richtarik}, {\em Randomized iterative methods for linear systems}, SIAM, 
  (2015).



\end{thebibliography}

\end{document}



